---
layout: post
title:  "윈도우 환경에서의 Kafka 설치 및 테스트 입니다."
date:   2020-01-07
desc: "윈도우 환경에서의 Kafka 설치"
keywords: "Kafka"
categories: [Etc]
tags: [Kafka,Server]
icon: server
---
안녕하세요 Dev JaeIn 입니다.

최근 진행했던 Kafka 윈도우 설치 후 테스트를 진행하여 내용을 공유합니다.

***

#### 설치 및 테스트 전에 카프카와 zookeeper에 대해 알아보고 진행하겠습니다. 

* ## 카프카와 시스템간의 대략적인 구성도
  
  ![](/assets/img/blog/2020-01-07-01-Kafka-Setup/2020-01-07-13-13-39.png){: .img-center}

* ## 카프카

   - 메시징 큐의 일종입니다. 
  
	- 그리고 다른 메시징 큐 activemq, rabbitmq 대비 우수한 TPS 를 나타냅니다.따라서 대용량의 실시간 로그 처리에 특화되어 있습니다.
	 
	- 메시지를 기본적으로 저장하는 기존 메시징 시스템과는 달리 파일 시스템에 저장합니다. 따라서 데이터 유실에 안전합니다.

   - 구성은 Producer, Broker(kafka 서버) , Consumer 로 되어있습니다.

   - 기존 메시징 시스템과의 차이점

![](/assets/img/blog/2020-01-07-01-Kafka-Setup/2020-01-07-13-31-07.png){: .img-center}

   기존시스템은 Broker가 Consumer 에게 들어오는 메시지를 Push 방식으로 진행.
  
   카프카의 Consumer가 브로커로부터 메시지를 가져오기 때문에 자신이 처리량 만큼 처리 할 수 있어 최적의 성능을 낼 수 있습니다.

  * 성능비교 그래프
  
  ![](/assets/img/blog/2020-01-07-01-Kafka-Setup/2020-01-07-13-02-15.png){: .img-center}

*** 

* ## Zookeeper

   ![](/assets/img/blog/2020-01-07-01-Kafka-Setup/2020-01-07-13-06-12.png){: .img-center}

	- Zookeeper 란 카프카 서버(클러스터)를 관리해주는 것이다. 
   
   - 예를들어, 카프카 서버가 Broker 1,2,3 이렇게 3대가 존재합니다. 클러스터가 되어있는 상태이므로 모든 데이터는 공유가 됩니다.
	
   - 만약 1번이 리더고 2,3이 팔로워이면 1번 서버가 죽으면 2번 서버가 리더가 되는 방식으로 진행됩니다. 
   
   - 1번 서버가 재시작 되면 1번은 이제 팔로워가 됩니다. 
   
   - 이런 역할을 해주는 것이 Zookeeper 입니다.

    
*** 

* ## Kafka 설치 및 테스트 진행

1.카프카 다운로드를 진행합니다.

<https://kafka.apache.org/downloads> 에서 다운로드를 진행하면 됩니다. 

단, 주의할점이 있습니다. src를 다운로드 하지 말고 Binary 다운로드를 진행해야 합니다.

저는 src 다운로드 후 진행하려 하니 다음와 같은 예외가 나와 서버가 수행되지 않고 많은 어려움을 겪었습니다.

![](/assets/img/blog/2020-01-07-01-Kafka-Setup/2020-01-07-13-54-36.png){: .img-center}

그래서 제가 다운로드한 파일을 보여드리겠습니다.

![](/assets/img/blog/2020-01-07-01-Kafka-Setup/2020-01-07-13-09-26.png){: .img-center}

다운로드 한 후 압축을 해제하면 윈도우 전용 폴더가 존재합니다.

저의 경로는 압축파일 폴더에서 부터 kafka_2.12-2.4.0\bin\windows 으로 존재합니다.

2.카프카를 다운로드 하면 zookeeper도 함께 있습니다. 먼저 zookeeper 를 수행합니다.

앞서 설명드린것과 같이 zookeeper가 카프카를 관리해주니 zookeeper가 먼저 수행 된 후 카프카가 수행 가능합니다.

수행 명령어는 다음과 같습니다. 저는 full path를 통해 CMD 창에서 수행했습니다. 각자 카프카 압축파일을 해제한 경로만 설정해서 변경 후 사용하시면 됩니다.

```
C:\SpringBoot\kafka\kafka_2.12-2.4.0\bin\windows\zookeeper-server-start.bat C:\SpringBoot\kafka\kafka_2.12-2.4.0\config\zookeeper.properties
```

수행 후 화면

![](/assets/img/blog/2020-01-07-01-Kafka-Setup/2020-01-07-13-12-21.png){: .img-center}

3.이번에는 카프카를 수행합니다. 

```
C:\SpringBoot\kafka\kafka_2.12-2.4.0\bin\windows\kafka-server-start.bat C:\SpringBoot\kafka\kafka_2.12-2.4.0\config\server.properties
```

수행 후 화면

![](/assets/img/blog/2020-01-07-01-Kafka-Setup/2020-01-07-13-12-14.png){: .img-center}


4.topic 생성

토픽은 카프카서버에 데이터를 저장하는 공간 이라고 생각하시면 됩니다. 

토픽을 생성해야 해당 토픽으로 producer가 데이터를 전송하고 consumer는 토픽을 통해 데이터를 가져옵니다.

```
C:\SpringBoot\kafka\kafka_2.12-2.4.0\bin\windows>kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic [topicname]
```

수행하면 다음과 같이 Created [topicname] 이 나타납니다.

![](/assets/img/blog/2020-01-07-01-Kafka-Setup/2020-01-07-13-34-39.png){: .img-center}

생성된 토픽 확인 명령어

다음 명령어 부터는 

## cmd창에서 kafka_2.12-2.4.0\bin\windows 경로 이동 후 진행하겠습니다.

각자 설치된 경로로 이동 후 명령어를 수행하시거나 아니면 full path로 하셔도 됩니다.

```
kafka-topics.bat --list --zookeeper localhost:2181
```

![](/assets/img/blog/2020-01-07-01-Kafka-Setup/2020-01-07-13-38-33.png){: .img-center}

5.Consumer 생성을 진행합니다. 실제 Producer에서 넘어오는 데이터 확인을 위해 수행 후 열어둡니다.

만약 수행이 안된다면 cmd 창의 경로를 확인해주세요.

```
kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic [topicName]
```

[topicName] 에 방금 생성했던 topic 명을 적어주시면 됩니다.

수행하면 아무것도 반응이 없는 상태로 있습니다. 

![](/assets/img/blog/2020-01-07-01-Kafka-Setup/2020-01-07-13-38-46.png){: .img-center}

6.Producer 생성

cmd창에서 다음 명령어를 수행하면 입력 할 수 있는 상태로 변경됩니다.

```
kafka-console-producer.bat --broker-list localhost:9092 --topic [topicName]
```

![](/assets/img/blog/2020-01-07-01-Kafka-Setup/2020-01-07-13-45-02.png){: .img-center}

7.테스트

이제 마지막 단계입니다. Producer 창에서 메시지를 입력하면 Consumer 로 잘 전달되는지 진행합니다.

![](/assets/img/blog/2020-01-07-01-Kafka-Setup/2020-01-07-13-48-20.png){: .img-center}

정상적으로 메시지가 전달되는 것을 확인 할 수 있습니다.

***

### 정리

*** 

많은 유저를 보유하는 서비스에서 카프카를 이용한다면 통합로그 관리가 가능합니다.

그리고 Queue 방식이므로 먼저 접속한 사용자에게 우선순위를 부여할때도 사용가능하지 않을까 생각합니다.

다음 포스팅에선 실제 어플리케이션(Spring)과 Kafka 연동해 대해 포스팅을 진행하겠습니다.

읽어주셔서 감사합니다!

